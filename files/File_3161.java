/*
 * <summary></summary>
 * <author>He Han</author>
 * <email>hankcs.cn@gmail.com</email>
 * <create-date>2014/10/17 19:02</create-date>
 *
 * <copyright file="HanLP.java" company="ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸">
 * Copyright (c) 2003-2014, ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸. All Right Reserved, http://www.linrunsoft.com/
 * This source is subject to the LinrunSpace License. Please contact ä¸Šæµ·æž—åŽŸä¿¡æ?¯ç§‘æŠ€æœ‰é™?å…¬å?¸ to get more information.
 * </copyright>
 */
package com.hankcs.hanlp;

import com.hankcs.hanlp.corpus.dependency.CoNll.CoNLLSentence;
import com.hankcs.hanlp.corpus.io.IIOAdapter;
import com.hankcs.hanlp.dependency.nnparser.NeuralNetworkDependencyParser;
import com.hankcs.hanlp.dependency.perceptron.parser.KBeamArcEagerDependencyParser;
import com.hankcs.hanlp.dictionary.py.Pinyin;
import com.hankcs.hanlp.dictionary.py.PinyinDictionary;
import com.hankcs.hanlp.dictionary.ts.*;
import com.hankcs.hanlp.mining.phrase.IPhraseExtractor;
import com.hankcs.hanlp.mining.phrase.MutualInformationEntropyPhraseExtractor;
import com.hankcs.hanlp.mining.word.NewWordDiscover;
import com.hankcs.hanlp.mining.word.WordInfo;
import com.hankcs.hanlp.model.crf.CRFLexicalAnalyzer;
import com.hankcs.hanlp.model.perceptron.PerceptronLexicalAnalyzer;
import com.hankcs.hanlp.seg.CRF.CRFSegment;
import com.hankcs.hanlp.seg.HMM.HMMSegment;
import com.hankcs.hanlp.seg.NShort.NShortSegment;
import com.hankcs.hanlp.seg.Other.DoubleArrayTrieSegment;
import com.hankcs.hanlp.seg.Segment;
import com.hankcs.hanlp.seg.Viterbi.ViterbiSegment;
import com.hankcs.hanlp.seg.common.Term;
import com.hankcs.hanlp.summary.TextRankKeyword;
import com.hankcs.hanlp.summary.TextRankSentence;
import com.hankcs.hanlp.tokenizer.StandardTokenizer;
import com.hankcs.hanlp.utility.Predefine;
import com.hankcs.hanlp.utility.TextUtility;

import java.io.*;
import java.lang.reflect.Constructor;
import java.util.List;
import java.util.Properties;
import java.util.logging.Level;

import static com.hankcs.hanlp.utility.Predefine.logger;

/**
 * HanLP: Han Language Processing <br>
 * æ±‰è¯­è¨€å¤„ç?†åŒ… <br>
 * å¸¸ç”¨æŽ¥å?£å·¥å…·ç±»
 *
 * @author hankcs
 */
public class HanLP
{
    /**
     * åº“çš„å…¨å±€é…?ç½®ï¼Œæ—¢å?¯ä»¥ç”¨ä»£ç ?ä¿®æ”¹ï¼Œä¹Ÿå?¯ä»¥é€šè¿‡hanlp.propertiesé…?ç½®ï¼ˆæŒ‰ç…§ å?˜é‡?å??=å€¼ çš„å½¢å¼?ï¼‰
     */
    public static final class Config
    {
        /**
         * å¼€å?‘æ¨¡å¼?
         */
        public static boolean DEBUG = false;
        /**
         * æ ¸å¿ƒè¯?å…¸è·¯å¾„
         */
        public static String CoreDictionaryPath = "data/dictionary/CoreNatureDictionary.txt";
        /**
         * æ ¸å¿ƒè¯?å…¸è¯?æ€§è½¬ç§»çŸ©é˜µè·¯å¾„
         */
        public static String CoreDictionaryTransformMatrixDictionaryPath = "data/dictionary/CoreNatureDictionary.tr.txt";
        /**
         * ç”¨æˆ·è‡ªå®šä¹‰è¯?å…¸è·¯å¾„
         */
        public static String CustomDictionaryPath[] = new String[]{"data/dictionary/custom/CustomDictionary.txt"};
        /**
         * 2å…ƒè¯­æ³•è¯?å…¸è·¯å¾„
         */
        public static String BiGramDictionaryPath = "data/dictionary/CoreNatureDictionary.ngram.txt";

        /**
         * å?œç”¨è¯?è¯?å…¸è·¯å¾„
         */
        public static String CoreStopWordDictionaryPath = "data/dictionary/stopwords.txt";
        /**
         * å?Œä¹‰è¯?è¯?å…¸è·¯å¾„
         */
        public static String CoreSynonymDictionaryDictionaryPath = "data/dictionary/synonym/CoreSynonym.txt";
        /**
         * äººå??è¯?å…¸è·¯å¾„
         */
        public static String PersonDictionaryPath = "data/dictionary/person/nr.txt";
        /**
         * äººå??è¯?å…¸è½¬ç§»çŸ©é˜µè·¯å¾„
         */
        public static String PersonDictionaryTrPath = "data/dictionary/person/nr.tr.txt";
        /**
         * åœ°å??è¯?å…¸è·¯å¾„
         */
        public static String PlaceDictionaryPath = "data/dictionary/place/ns.txt";
        /**
         * åœ°å??è¯?å…¸è½¬ç§»çŸ©é˜µè·¯å¾„
         */
        public static String PlaceDictionaryTrPath = "data/dictionary/place/ns.tr.txt";
        /**
         * åœ°å??è¯?å…¸è·¯å¾„
         */
        public static String OrganizationDictionaryPath = "data/dictionary/organization/nt.txt";
        /**
         * åœ°å??è¯?å…¸è½¬ç§»çŸ©é˜µè·¯å¾„
         */
        public static String OrganizationDictionaryTrPath = "data/dictionary/organization/nt.tr.txt";
        /**
         * ç®€ç¹?è½¬æ?¢è¯?å…¸æ ¹ç›®å½•
         */
        public static String tcDictionaryRoot = "data/dictionary/tc/";

        /**
         * æ‹¼éŸ³è¯?å…¸è·¯å¾„
         */
        public static String PinyinDictionaryPath = "data/dictionary/pinyin/pinyin.txt";

        /**
         * éŸ³è¯‘äººå??è¯?å…¸
         */
        public static String TranslatedPersonDictionaryPath = "data/dictionary/person/nrf.txt";

        /**
         * æ—¥æœ¬äººå??è¯?å…¸è·¯å¾„
         */
        public static String JapanesePersonDictionaryPath = "data/dictionary/person/nrj.txt";

        /**
         * å­—ç¬¦ç±»åž‹å¯¹åº”è¡¨
         */
        public static String CharTypePath = "data/dictionary/other/CharType.bin";

        /**
         * å­—ç¬¦æ­£è§„åŒ–è¡¨ï¼ˆå…¨è§’è½¬å?Šè§’ï¼Œç¹?ä½“è½¬ç®€ä½“ï¼‰
         */
        public static String CharTablePath = "data/dictionary/other/CharTable.txt";

        /**
         * è¯?æ€§æ ‡æ³¨é›†æ??è¿°è¡¨ï¼Œç”¨æ?¥è¿›è¡Œä¸­è‹±æ˜ å°„ï¼ˆå¯¹äºŽNatureè¯?æ€§ï¼Œå?¯ç›´æŽ¥å?‚è€ƒNature.javaä¸­çš„æ³¨é‡Šï¼‰
         */
        public static String PartOfSpeechTagDictionary = "data/dictionary/other/TagPKU98.csv";

        /**
         * è¯?-è¯?æ€§-ä¾?å­˜å…³ç³»æ¨¡åž‹
         */
        public static String WordNatureModelPath = "data/model/dependency/WordNature.txt";

        /**
         * æœ€å¤§ç†µ-ä¾?å­˜å…³ç³»æ¨¡åž‹
         * @deprecated å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨{@link KBeamArcEagerDependencyParser}ã€‚æœªæ?¥ç‰ˆæœ¬å°†ä¸?å†?å?‘å¸ƒè¯¥æ¨¡åž‹ï¼Œå¹¶åˆ é™¤é…?ç½®é¡¹
         */
        public static String MaxEntModelPath = "data/model/dependency/MaxEntModel.txt";
        /**
         * ç¥žç»?ç½‘ç»œä¾?å­˜æ¨¡åž‹è·¯å¾„
         */
        public static String NNParserModelPath = "data/model/dependency/NNParserModel.txt";
        /**
         * æ„ŸçŸ¥æœºArcEagerä¾?å­˜æ¨¡åž‹è·¯å¾„
         */
        public static String PerceptronParserModelPath = "data/model/dependency/perceptron.bin";
        /**
         * CRFåˆ†è¯?æ¨¡åž‹
         *
         * @deprecated å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨{@link com.hankcs.hanlp.model.crf.CRFLexicalAnalyzer}ã€‚æœªæ?¥ç‰ˆæœ¬å°†ä¸?å†?å?‘å¸ƒè¯¥æ¨¡åž‹ï¼Œå¹¶åˆ é™¤é…?ç½®é¡¹
         */
        public static String CRFSegmentModelPath = "data/model/segment/CRFSegmentModel.txt";
        /**
         * HMMåˆ†è¯?æ¨¡åž‹
         *
         * @deprecated å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨{@link PerceptronLexicalAnalyzer}
         */
        public static String HMMSegmentModelPath = "data/model/segment/HMMSegmentModel.bin";
        /**
         * CRFåˆ†è¯?æ¨¡åž‹
         */
        public static String CRFCWSModelPath = "data/model/crf/pku199801/cws.txt";
        /**
         * CRFè¯?æ€§æ ‡æ³¨æ¨¡åž‹
         */
        public static String CRFPOSModelPath = "data/model/crf/pku199801/pos.txt";
        /**
         * CRFå‘½å??å®žä½“è¯†åˆ«æ¨¡åž‹
         */
        public static String CRFNERModelPath = "data/model/crf/pku199801/ner.txt";
        /**
         * æ„ŸçŸ¥æœºåˆ†è¯?æ¨¡åž‹
         */
        public static String PerceptronCWSModelPath = "data/model/perceptron/large/cws.bin";
        /**
         * æ„ŸçŸ¥æœºè¯?æ€§æ ‡æ³¨æ¨¡åž‹
         */
        public static String PerceptronPOSModelPath = "data/model/perceptron/pku1998/pos.bin";
        /**
         * æ„ŸçŸ¥æœºå‘½å??å®žä½“è¯†åˆ«æ¨¡åž‹
         */
        public static String PerceptronNERModelPath = "data/model/perceptron/pku1998/ner.bin";
        /**
         * åˆ†è¯?ç»“æžœæ˜¯å?¦å±•ç¤ºè¯?æ€§
         */
        public static boolean ShowTermNature = true;
        /**
         * æ˜¯å?¦æ‰§è¡Œå­—ç¬¦æ­£è§„åŒ–ï¼ˆç¹?ä½“->ç®€ä½“ï¼Œå…¨è§’->å?Šè§’ï¼Œå¤§å†™->å°?å†™ï¼‰ï¼Œåˆ‡æ?¢é…?ç½®å?Žå¿…é¡»åˆ CustomDictionary.txt.binç¼“å­˜
         */
        public static boolean Normalization = false;
        /**
         * IOé€‚é…?å™¨ï¼ˆé»˜è®¤nullï¼Œè¡¨ç¤ºä»Žæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¯»å?–ï¼‰ï¼Œå®žçŽ°com.hankcs.hanlp.corpus.io.IIOAdapteræŽ¥å?£
         * ä»¥åœ¨ä¸?å?Œçš„å¹³å?°ï¼ˆHadoopã€?Redisç­‰ï¼‰ä¸Šè¿?è¡ŒHanLP
         */
        public static IIOAdapter IOAdapter;

        static
        {
            // è‡ªåŠ¨è¯»å?–é…?ç½®
            Properties p = new Properties();
            try
            {
                ClassLoader loader = Thread.currentThread().getContextClassLoader();
                if (loader == null)
                {  // IKVM (v.0.44.0.5) doesn't set context classloader
                    loader = HanLP.Config.class.getClassLoader();
                }
                try
                {
                    p.load(new InputStreamReader(Predefine.HANLP_PROPERTIES_PATH == null ?
                                                     loader.getResourceAsStream("hanlp.properties") :
                                                     new FileInputStream(Predefine.HANLP_PROPERTIES_PATH)
                        , "UTF-8"));
                }
                catch (Exception e)
                {
                    String HANLP_ROOT = System.getProperty("HANLP_ROOT");
                    if (HANLP_ROOT == null) HANLP_ROOT = System.getenv("HANLP_ROOT");
                    if (HANLP_ROOT != null)
                    {
                        HANLP_ROOT = HANLP_ROOT.trim();
                        p = new Properties();
                        p.setProperty("root", HANLP_ROOT);
                        logger.info("ä½¿ç”¨çŽ¯å¢ƒå?˜é‡? HANLP_ROOT=" + HANLP_ROOT);
                    }
                    else throw e;
                }
                String root = p.getProperty("root", "").replaceAll("\\\\", "/");
                if (root.length() > 0 && !root.endsWith("/")) root += "/";
                CoreDictionaryPath = root + p.getProperty("CoreDictionaryPath", CoreDictionaryPath);
                CoreDictionaryTransformMatrixDictionaryPath = root + p.getProperty("CoreDictionaryTransformMatrixDictionaryPath", CoreDictionaryTransformMatrixDictionaryPath);
                BiGramDictionaryPath = root + p.getProperty("BiGramDictionaryPath", BiGramDictionaryPath);
                CoreStopWordDictionaryPath = root + p.getProperty("CoreStopWordDictionaryPath", CoreStopWordDictionaryPath);
                CoreSynonymDictionaryDictionaryPath = root + p.getProperty("CoreSynonymDictionaryDictionaryPath", CoreSynonymDictionaryDictionaryPath);
                PersonDictionaryPath = root + p.getProperty("PersonDictionaryPath", PersonDictionaryPath);
                PersonDictionaryTrPath = root + p.getProperty("PersonDictionaryTrPath", PersonDictionaryTrPath);
                String[] pathArray = p.getProperty("CustomDictionaryPath", "data/dictionary/custom/CustomDictionary.txt").split(";");
                String prePath = root;
                for (int i = 0; i < pathArray.length; ++i)
                {
                    if (pathArray[i].startsWith(" "))
                    {
                        pathArray[i] = prePath + pathArray[i].trim();
                    }
                    else
                    {
                        pathArray[i] = root + pathArray[i];
                        int lastSplash = pathArray[i].lastIndexOf('/');
                        if (lastSplash != -1)
                        {
                            prePath = pathArray[i].substring(0, lastSplash + 1);
                        }
                    }
                }
                CustomDictionaryPath = pathArray;
                tcDictionaryRoot = root + p.getProperty("tcDictionaryRoot", tcDictionaryRoot);
                if (!tcDictionaryRoot.endsWith("/")) tcDictionaryRoot += '/';
                PinyinDictionaryPath = root + p.getProperty("PinyinDictionaryPath", PinyinDictionaryPath);
                TranslatedPersonDictionaryPath = root + p.getProperty("TranslatedPersonDictionaryPath", TranslatedPersonDictionaryPath);
                JapanesePersonDictionaryPath = root + p.getProperty("JapanesePersonDictionaryPath", JapanesePersonDictionaryPath);
                PlaceDictionaryPath = root + p.getProperty("PlaceDictionaryPath", PlaceDictionaryPath);
                PlaceDictionaryTrPath = root + p.getProperty("PlaceDictionaryTrPath", PlaceDictionaryTrPath);
                OrganizationDictionaryPath = root + p.getProperty("OrganizationDictionaryPath", OrganizationDictionaryPath);
                OrganizationDictionaryTrPath = root + p.getProperty("OrganizationDictionaryTrPath", OrganizationDictionaryTrPath);
                CharTypePath = root + p.getProperty("CharTypePath", CharTypePath);
                CharTablePath = root + p.getProperty("CharTablePath", CharTablePath);
                PartOfSpeechTagDictionary = root + p.getProperty("PartOfSpeechTagDictionary", PartOfSpeechTagDictionary);
                WordNatureModelPath = root + p.getProperty("WordNatureModelPath", WordNatureModelPath);
                MaxEntModelPath = root + p.getProperty("MaxEntModelPath", MaxEntModelPath);
                NNParserModelPath = root + p.getProperty("NNParserModelPath", NNParserModelPath);
                PerceptronParserModelPath = root + p.getProperty("PerceptronParserModelPath", PerceptronParserModelPath);
                CRFSegmentModelPath = root + p.getProperty("CRFSegmentModelPath", CRFSegmentModelPath);
                HMMSegmentModelPath = root + p.getProperty("HMMSegmentModelPath", HMMSegmentModelPath);
                CRFCWSModelPath = root + p.getProperty("CRFCWSModelPath", CRFCWSModelPath);
                CRFPOSModelPath = root + p.getProperty("CRFPOSModelPath", CRFPOSModelPath);
                CRFNERModelPath = root + p.getProperty("CRFNERModelPath", CRFNERModelPath);
                PerceptronCWSModelPath = root + p.getProperty("PerceptronCWSModelPath", PerceptronCWSModelPath);
                PerceptronPOSModelPath = root + p.getProperty("PerceptronPOSModelPath", PerceptronPOSModelPath);
                PerceptronNERModelPath = root + p.getProperty("PerceptronNERModelPath", PerceptronNERModelPath);
                ShowTermNature = "true".equals(p.getProperty("ShowTermNature", "true"));
                Normalization = "true".equals(p.getProperty("Normalization", "false"));
                String ioAdapterClassName = p.getProperty("IOAdapter");
                if (ioAdapterClassName != null)
                {
                    try
                    {
                        Class<?> clazz = Class.forName(ioAdapterClassName);
                        Constructor<?> ctor = clazz.getConstructor();
                        Object instance = ctor.newInstance();
                        if (instance != null) IOAdapter = (IIOAdapter) instance;
                    }
                    catch (ClassNotFoundException e)
                    {
                        logger.warning(String.format("æ‰¾ä¸?åˆ°IOé€‚é…?å™¨ç±»ï¼š %s ï¼Œè¯·æ£€æŸ¥ç¬¬ä¸‰æ–¹æ?’ä»¶jaråŒ…", ioAdapterClassName));
                    }
                    catch (NoSuchMethodException e)
                    {
                        logger.warning(String.format("å·¥åŽ‚ç±»[%s]æ²¡æœ‰é»˜è®¤æž„é€ æ–¹æ³•ï¼Œä¸?ç¬¦å?ˆè¦?æ±‚", ioAdapterClassName));
                    }
                    catch (SecurityException e)
                    {
                        logger.warning(String.format("å·¥åŽ‚ç±»[%s]é»˜è®¤æž„é€ æ–¹æ³•æ— æ³•è®¿é—®ï¼Œä¸?ç¬¦å?ˆè¦?æ±‚", ioAdapterClassName));
                    }
                    catch (Exception e)
                    {
                        logger.warning(String.format("å·¥åŽ‚ç±»[%s]æž„é€ å¤±è´¥ï¼š%s\n", ioAdapterClassName, TextUtility.exceptionToString(e)));
                    }
                }
            }
            catch (Exception e)
            {
                if (new File("data/dictionary/CoreNatureDictionary.tr.txt").isFile())
                {
                    logger.info("ä½¿ç”¨å½“å‰?ç›®å½•ä¸‹çš„data");
                }
                else
                {
                    StringBuilder sbInfo = new StringBuilder("========Tips========\nè¯·å°†hanlp.propertiesæ”¾åœ¨ä¸‹åˆ—ç›®å½•ï¼š\n"); // æ‰“å?°ä¸€äº›å?‹å¥½çš„tips
                    if (new File("src/main/java").isDirectory())
                    {
                        sbInfo.append("src/main/resources");
                    }
                    else
                    {
                        String classPath = (String) System.getProperties().get("java.class.path");
                        if (classPath != null)
                        {
                            for (String path : classPath.split(File.pathSeparator))
                            {
                                if (new File(path).isDirectory())
                                {
                                    sbInfo.append(path).append('\n');
                                }
                            }
                        }
                        sbInfo.append("Webé¡¹ç›®åˆ™è¯·æ”¾åˆ°ä¸‹åˆ—ç›®å½•ï¼š\n" +
                                          "Webapp/WEB-INF/lib\n" +
                                          "Webapp/WEB-INF/classes\n" +
                                          "Appserver/lib\n" +
                                          "JRE/lib\n");
                        sbInfo.append("å¹¶ä¸”ç¼–è¾‘root=PARENT/path/to/your/data\n");
                        sbInfo.append("çŽ°åœ¨HanLPå°†å°?è¯•ä»Ž").append(System.getProperties().get("user.dir")).append("è¯»å?–dataâ€¦â€¦");
                    }
                    logger.severe("æ²¡æœ‰æ‰¾åˆ°hanlp.propertiesï¼Œå?¯èƒ½ä¼šå¯¼è‡´æ‰¾ä¸?åˆ°data\n" + sbInfo);
                }
            }
        }

        /**
         * å¼€å?¯è°ƒè¯•æ¨¡å¼?(ä¼šé™?ä½Žæ€§èƒ½)
         */
        public static void enableDebug()
        {
            enableDebug(true);
        }

        /**
         * å¼€å?¯è°ƒè¯•æ¨¡å¼?(ä¼šé™?ä½Žæ€§èƒ½)
         *
         * @param enable
         */
        public static void enableDebug(boolean enable)
        {
            DEBUG = enable;
            if (DEBUG)
            {
                logger.setLevel(Level.ALL);
            }
            else
            {
                logger.setLevel(Level.OFF);
            }
        }
    }

    /**
     * å·¥å…·ç±»ï¼Œä¸?éœ€è¦?ç”Ÿæˆ?å®žä¾‹
     */
    private HanLP()
    {
    }

    /**
     * ç¹?è½¬ç®€
     *
     * @param traditionalChineseString ç¹?ä½“ä¸­æ–‡
     * @return ç®€ä½“ä¸­æ–‡
     */
    public static String convertToSimplifiedChinese(String traditionalChineseString)
    {
        return TraditionalChineseDictionary.convertToSimplifiedChinese(traditionalChineseString.toCharArray());
    }

    /**
     * ç®€è½¬ç¹?
     *
     * @param simplifiedChineseString ç®€ä½“ä¸­æ–‡
     * @return ç¹?ä½“ä¸­æ–‡
     */
    public static String convertToTraditionalChinese(String simplifiedChineseString)
    {
        return SimplifiedChineseDictionary.convertToTraditionalChinese(simplifiedChineseString.toCharArray());
    }

    /**
     * ç®€è½¬ç¹?,æ˜¯{@link com.hankcs.hanlp.HanLP#convertToTraditionalChinese(java.lang.String)}çš„ç®€ç§°
     *
     * @param s ç®€ä½“ä¸­æ–‡
     * @return ç¹?ä½“ä¸­æ–‡(å¤§é™†æ ‡å‡†)
     */
    public static String s2t(String s)
    {
        return HanLP.convertToTraditionalChinese(s);
    }

    /**
     * ç¹?è½¬ç®€,æ˜¯{@link HanLP#convertToSimplifiedChinese(String)}çš„ç®€ç§°
     *
     * @param t ç¹?ä½“ä¸­æ–‡(å¤§é™†æ ‡å‡†)
     * @return ç®€ä½“ä¸­æ–‡
     */
    public static String t2s(String t)
    {
        return HanLP.convertToSimplifiedChinese(t);
    }

    /**
     * ç°¡é«”åˆ°è‡ºç?£æ­£é«”
     *
     * @param s ç°¡é«”
     * @return è‡ºç?£æ­£é«”
     */
    public static String s2tw(String s)
    {
        return SimplifiedToTaiwanChineseDictionary.convertToTraditionalTaiwanChinese(s);
    }

    /**
     * è‡ºç?£æ­£é«”åˆ°ç°¡é«”
     *
     * @param tw è‡ºç?£æ­£é«”
     * @return ç°¡é«”
     */
    public static String tw2s(String tw)
    {
        return TaiwanToSimplifiedChineseDictionary.convertToSimplifiedChinese(tw);
    }

    /**
     * ç°¡é«”åˆ°é¦™æ¸¯ç¹?é«”
     *
     * @param s ç°¡é«”
     * @return é¦™æ¸¯ç¹?é«”
     */
    public static String s2hk(String s)
    {
        return SimplifiedToHongKongChineseDictionary.convertToTraditionalHongKongChinese(s);
    }

    /**
     * é¦™æ¸¯ç¹?é«”åˆ°ç°¡é«”
     *
     * @param hk é¦™æ¸¯ç¹?é«”
     * @return ç°¡é«”
     */
    public static String hk2s(String hk)
    {
        return HongKongToSimplifiedChineseDictionary.convertToSimplifiedChinese(hk);
    }

    /**
     * ç¹?é«”åˆ°è‡ºç?£æ­£é«”
     *
     * @param t ç¹?é«”
     * @return è‡ºç?£æ­£é«”
     */
    public static String t2tw(String t)
    {
        return TraditionalToTaiwanChineseDictionary.convertToTaiwanChinese(t);
    }

    /**
     * è‡ºç?£æ­£é«”åˆ°ç¹?é«”
     *
     * @param tw è‡ºç?£æ­£é«”
     * @return ç¹?é«”
     */
    public static String tw2t(String tw)
    {
        return TaiwanToTraditionalChineseDictionary.convertToTraditionalChinese(tw);
    }

    /**
     * ç¹?é«”åˆ°é¦™æ¸¯ç¹?é«”
     *
     * @param t ç¹?é«”
     * @return é¦™æ¸¯ç¹?é«”
     */
    public static String t2hk(String t)
    {
        return TraditionalToHongKongChineseDictionary.convertToHongKongTraditionalChinese(t);
    }

    /**
     * é¦™æ¸¯ç¹?é«”åˆ°ç¹?é«”
     *
     * @param hk é¦™æ¸¯ç¹?é«”
     * @return ç¹?é«”
     */
    public static String hk2t(String hk)
    {
        return HongKongToTraditionalChineseDictionary.convertToTraditionalChinese(hk);
    }

    /**
     * é¦™æ¸¯ç¹?é«”åˆ°è‡ºç?£æ­£é«”
     *
     * @param hk é¦™æ¸¯ç¹?é«”
     * @return è‡ºç?£æ­£é«”
     */
    public static String hk2tw(String hk)
    {
        return HongKongToTaiwanChineseDictionary.convertToTraditionalTaiwanChinese(hk);
    }

    /**
     * è‡ºç?£æ­£é«”åˆ°é¦™æ¸¯ç¹?é«”
     *
     * @param tw è‡ºç?£æ­£é«”
     * @return é¦™æ¸¯ç¹?é«”
     */
    public static String tw2hk(String tw)
    {
        return TaiwanToHongKongChineseDictionary.convertToTraditionalHongKongChinese(tw);
    }

    /**
     * è½¬åŒ–ä¸ºæ‹¼éŸ³
     *
     * @param text       æ–‡æœ¬
     * @param separator  åˆ†éš”ç¬¦
     * @param remainNone æœ‰äº›å­—æ²¡æœ‰æ‹¼éŸ³ï¼ˆå¦‚æ ‡ç‚¹ï¼‰ï¼Œæ˜¯å?¦ä¿?ç•™å®ƒä»¬çš„æ‹¼éŸ³ï¼ˆtrueç”¨noneè¡¨ç¤ºï¼Œfalseç”¨åŽŸå­—ç¬¦è¡¨ç¤ºï¼‰
     * @return ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”±[æ‹¼éŸ³][åˆ†éš”ç¬¦][æ‹¼éŸ³]æž„æˆ?
     */
    public static String convertToPinyinString(String text, String separator, boolean remainNone)
    {
        List<Pinyin> pinyinList = PinyinDictionary.convertToPinyin(text, true);
        int length = pinyinList.size();
        StringBuilder sb = new StringBuilder(length * (5 + separator.length()));
        int i = 1;
        for (Pinyin pinyin : pinyinList)
        {

            if (pinyin == Pinyin.none5 && !remainNone)
            {
                sb.append(text.charAt(i - 1));
            }
            else sb.append(pinyin.getPinyinWithoutTone());
            if (i < length)
            {
                sb.append(separator);
            }
            ++i;
        }
        return sb.toString();
    }

    /**
     * è½¬åŒ–ä¸ºæ‹¼éŸ³
     *
     * @param text å¾…è§£æž?çš„æ–‡æœ¬
     * @return ä¸€ä¸ªæ‹¼éŸ³åˆ—è¡¨
     */
    public static List<Pinyin> convertToPinyinList(String text)
    {
        return PinyinDictionary.convertToPinyin(text);
    }

    /**
     * è½¬åŒ–ä¸ºæ‹¼éŸ³ï¼ˆé¦–å­—æ¯?ï¼‰
     *
     * @param text       æ–‡æœ¬
     * @param separator  åˆ†éš”ç¬¦
     * @param remainNone æœ‰äº›å­—æ²¡æœ‰æ‹¼éŸ³ï¼ˆå¦‚æ ‡ç‚¹ï¼‰ï¼Œæ˜¯å?¦ä¿?ç•™å®ƒä»¬ï¼ˆç”¨noneè¡¨ç¤ºï¼‰
     * @return ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”±[é¦–å­—æ¯?][åˆ†éš”ç¬¦][é¦–å­—æ¯?]æž„æˆ?
     */
    public static String convertToPinyinFirstCharString(String text, String separator, boolean remainNone)
    {
        List<Pinyin> pinyinList = PinyinDictionary.convertToPinyin(text, remainNone);
        int length = pinyinList.size();
        StringBuilder sb = new StringBuilder(length * (1 + separator.length()));
        int i = 1;
        for (Pinyin pinyin : pinyinList)
        {
            sb.append(pinyin.getFirstChar());
            if (i < length)
            {
                sb.append(separator);
            }
            ++i;
        }
        return sb.toString();
    }

    /**
     * åˆ†è¯?
     *
     * @param text æ–‡æœ¬
     * @return åˆ‡åˆ†å?Žçš„å?•è¯?
     */
    public static List<Term> segment(String text)
    {
        return StandardTokenizer.segment(text.toCharArray());
    }

    /**
     * åˆ›å»ºä¸€ä¸ªåˆ†è¯?å™¨<br>
     * è¿™æ˜¯ä¸€ä¸ªå·¥åŽ‚æ–¹æ³•<br>
     * ä¸Žç›´æŽ¥newä¸€ä¸ªåˆ†è¯?å™¨ç›¸æ¯”ï¼Œä½¿ç”¨æœ¬æ–¹æ³•çš„å¥½å¤„æ˜¯ï¼Œä»¥å?ŽHanLPå?‡çº§äº†ï¼Œæ€»èƒ½ç”¨ä¸Šæœ€å?ˆé€‚çš„åˆ†è¯?å™¨
     *
     * @return ä¸€ä¸ªåˆ†è¯?å™¨
     */
    public static Segment newSegment()
    {
        return new ViterbiSegment();   // Viterbiåˆ†è¯?å™¨æ˜¯ç›®å‰?æ•ˆçŽ‡å’Œæ•ˆæžœçš„æœ€ä½³å¹³è¡¡
    }

    /**
     * åˆ›å»ºä¸€ä¸ªåˆ†è¯?å™¨ï¼Œ
     * è¿™æ˜¯ä¸€ä¸ªå·¥åŽ‚æ–¹æ³•<br>
     *
     * @param algorithm åˆ†è¯?ç®—æ³•ï¼Œä¼ å…¥ç®—æ³•çš„ä¸­è‹±æ–‡å??éƒ½å?¯ä»¥ï¼Œå?¯é€‰åˆ—è¡¨ï¼š<br>
     *                  <ul>
     *                  <li>ç»´ç‰¹æ¯” (viterbi)ï¼šæ•ˆçŽ‡å’Œæ•ˆæžœçš„æœ€ä½³å¹³è¡¡</li>
     *                  <li>å?Œæ•°ç»„trieæ ‘ (dat)ï¼šæž?é€Ÿè¯?å…¸åˆ†è¯?ï¼Œå?ƒä¸‡å­—ç¬¦æ¯?ç§’</li>
     *                  <li>æ?¡ä»¶éš?æœºåœº (crf)ï¼šåˆ†è¯?ã€?è¯?æ€§æ ‡æ³¨ä¸Žå‘½å??å®žä½“è¯†åˆ«ç²¾åº¦éƒ½è¾ƒé«˜ï¼Œé€‚å?ˆè¦?æ±‚è¾ƒé«˜çš„NLPä»»åŠ¡</li>
     *                  <li>æ„ŸçŸ¥æœº (perceptron)ï¼šåˆ†è¯?ã€?è¯?æ€§æ ‡æ³¨ä¸Žå‘½å??å®žä½“è¯†åˆ«ï¼Œæ”¯æŒ?åœ¨çº¿å­¦ä¹ </li>
     *                  <li>Næœ€çŸ­è·¯ (nshort)ï¼šå‘½å??å®žä½“è¯†åˆ«ç¨?å¾®å¥½ä¸€äº›ï¼Œç‰ºç‰²äº†é€Ÿåº¦</li>
     *                  </ul>
     * @return ä¸€ä¸ªåˆ†è¯?å™¨
     */
    public static Segment newSegment(String algorithm)
    {
        if (algorithm == null)
        {
            throw new IllegalArgumentException(String.format("é?žæ³•å?‚æ•° algorithm == %s", algorithm));
        }
        algorithm = algorithm.toLowerCase();
        if ("viterbi".equals(algorithm) || "ç»´ç‰¹æ¯”".equals(algorithm))
            return new ViterbiSegment();   // Viterbiåˆ†è¯?å™¨æ˜¯ç›®å‰?æ•ˆçŽ‡å’Œæ•ˆæžœçš„æœ€ä½³å¹³è¡¡
        else if ("dat".equals(algorithm) || "å?Œæ•°ç»„trieæ ‘".equals(algorithm))
            return new DoubleArrayTrieSegment();
        else if ("nshort".equals(algorithm) || "næœ€çŸ­è·¯".equals(algorithm))
            return new NShortSegment();
        else if ("crf".equals(algorithm) || "æ?¡ä»¶éš?æœºåœº".equals(algorithm))
            try
            {
                return new CRFLexicalAnalyzer();
            }
            catch (IOException e)
            {
                logger.warning("CRFæ¨¡åž‹åŠ è½½å¤±è´¥");
                throw new RuntimeException(e);
            }
        else if ("perceptron".equals(algorithm) || "æ„ŸçŸ¥æœº".equals(algorithm))
        {
            try
            {
                return new PerceptronLexicalAnalyzer();
            }
            catch (IOException e)
            {
                logger.warning("æ„ŸçŸ¥æœºæ¨¡åž‹åŠ è½½å¤±è´¥");
                throw new RuntimeException(e);
            }
        }
        throw new IllegalArgumentException(String.format("é?žæ³•å?‚æ•° algorithm == %s", algorithm));
    }

    /**
     * ä¾?å­˜æ–‡æ³•åˆ†æž?
     *
     * @param sentence å¾…åˆ†æž?çš„å?¥å­?
     * @return CoNLLæ ¼å¼?çš„ä¾?å­˜å…³ç³»æ ‘
     */
    public static CoNLLSentence parseDependency(String sentence)
    {
        return NeuralNetworkDependencyParser.compute(sentence);
    }

    /**
     * æ??å?–çŸ­è¯­
     *
     * @param text æ–‡æœ¬
     * @param size éœ€è¦?å¤šå°‘ä¸ªçŸ­è¯­
     * @return ä¸€ä¸ªçŸ­è¯­åˆ—è¡¨ï¼Œå¤§å°? <= size
     */
    public static List<String> extractPhrase(String text, int size)
    {
        IPhraseExtractor extractor = new MutualInformationEntropyPhraseExtractor();
        return extractor.extractPhrase(text, size);
    }

    /**
     * æ??å?–è¯?è¯­
     *
     * @param text å¤§æ–‡æœ¬
     * @param size éœ€è¦?æ??å?–è¯?è¯­çš„æ•°é‡?
     * @return ä¸€ä¸ªè¯?è¯­åˆ—è¡¨
     */
    public static List<WordInfo> extractWords(String text, int size)
    {
        return extractWords(text, size, false);
    }

    /**
     * æ??å?–è¯?è¯­
     *
     * @param reader ä»ŽreaderèŽ·å?–æ–‡æœ¬
     * @param size   éœ€è¦?æ??å?–è¯?è¯­çš„æ•°é‡?
     * @return ä¸€ä¸ªè¯?è¯­åˆ—è¡¨
     */
    public static List<WordInfo> extractWords(BufferedReader reader, int size) throws IOException
    {
        return extractWords(reader, size, false);
    }

    /**
     * æ??å?–è¯?è¯­ï¼ˆæ–°è¯?å?‘çŽ°ï¼‰
     *
     * @param text         å¤§æ–‡æœ¬
     * @param size         éœ€è¦?æ??å?–è¯?è¯­çš„æ•°é‡?
     * @param newWordsOnly æ˜¯å?¦å?ªæ??å?–è¯?å…¸ä¸­æ²¡æœ‰çš„è¯?è¯­
     * @return ä¸€ä¸ªè¯?è¯­åˆ—è¡¨
     */
    public static List<WordInfo> extractWords(String text, int size, boolean newWordsOnly)
    {
        NewWordDiscover discover = new NewWordDiscover(4, 0.0f, .5f, 100f, newWordsOnly);
        return discover.discover(text, size);
    }

    /**
     * æ??å?–è¯?è¯­ï¼ˆæ–°è¯?å?‘çŽ°ï¼‰
     *
     * @param reader       ä»ŽreaderèŽ·å?–æ–‡æœ¬
     * @param size         éœ€è¦?æ??å?–è¯?è¯­çš„æ•°é‡?
     * @param newWordsOnly æ˜¯å?¦å?ªæ??å?–è¯?å…¸ä¸­æ²¡æœ‰çš„è¯?è¯­
     * @return ä¸€ä¸ªè¯?è¯­åˆ—è¡¨
     */
    public static List<WordInfo> extractWords(BufferedReader reader, int size, boolean newWordsOnly) throws IOException
    {
        NewWordDiscover discover = new NewWordDiscover(4, 0.0f, .5f, 100f, newWordsOnly);
        return discover.discover(reader, size);
    }

    /**
     * æ??å?–è¯?è¯­ï¼ˆæ–°è¯?å?‘çŽ°ï¼‰
     *
     * @param reader          ä»ŽreaderèŽ·å?–æ–‡æœ¬
     * @param size            éœ€è¦?æ??å?–è¯?è¯­çš„æ•°é‡?
     * @param newWordsOnly    æ˜¯å?¦å?ªæ??å?–è¯?å…¸ä¸­æ²¡æœ‰çš„è¯?è¯­
     * @param max_word_len    è¯?è¯­æœ€é•¿é•¿åº¦
     * @param min_freq        è¯?è¯­æœ€ä½Žé¢‘çŽ‡
     * @param min_entropy     è¯?è¯­æœ€ä½Žç†µ
     * @param min_aggregation è¯?è¯­æœ€ä½Žäº’ä¿¡æ?¯
     * @return ä¸€ä¸ªè¯?è¯­åˆ—è¡¨
     */
    public static List<WordInfo> extractWords(BufferedReader reader, int size, boolean newWordsOnly, int max_word_len, float min_freq, float min_entropy, float min_aggregation) throws IOException
    {
        NewWordDiscover discover = new NewWordDiscover(max_word_len, min_freq, min_entropy, min_aggregation, newWordsOnly);
        return discover.discover(reader, size);
    }

    /**
     * æ??å?–å…³é”®è¯?
     *
     * @param document æ–‡æ¡£å†…å®¹
     * @param size     å¸Œæœ›æ??å?–å‡ ä¸ªå…³é”®è¯?
     * @return ä¸€ä¸ªåˆ—è¡¨
     */
    public static List<String> extractKeyword(String document, int size)
    {
        return TextRankKeyword.getKeywordList(document, size);
    }

    /**
     * è‡ªåŠ¨æ‘˜è¦?
     * åˆ†å‰²ç›®æ ‡æ–‡æ¡£æ—¶çš„é»˜è®¤å?¥å­?åˆ†å‰²ç¬¦ä¸ºï¼Œ,ã€‚:ï¼šâ€œâ€?ï¼Ÿ?ï¼?!ï¼›;
     *
     * @param document ç›®æ ‡æ–‡æ¡£
     * @param size     éœ€è¦?çš„å…³é”®å?¥çš„ä¸ªæ•°
     * @return å…³é”®å?¥åˆ—è¡¨
     */
    public static List<String> extractSummary(String document, int size)
    {
        return TextRankSentence.getTopSentenceList(document, size);
    }

    /**
     * è‡ªåŠ¨æ‘˜è¦?
     * åˆ†å‰²ç›®æ ‡æ–‡æ¡£æ—¶çš„é»˜è®¤å?¥å­?åˆ†å‰²ç¬¦ä¸ºï¼Œ,ã€‚:ï¼šâ€œâ€?ï¼Ÿ?ï¼?!ï¼›;
     *
     * @param document   ç›®æ ‡æ–‡æ¡£
     * @param max_length éœ€è¦?æ‘˜è¦?çš„é•¿åº¦
     * @return æ‘˜è¦?æ–‡æœ¬
     */
    public static String getSummary(String document, int max_length)
    {
        // Parameter size in this method refers to the string length of the summary required;
        // The actual length of the summary generated may be short than the required length, but never longer;
        return TextRankSentence.getSummary(document, max_length);
    }

    /**
     * è‡ªåŠ¨æ‘˜è¦?
     *
     * @param document           ç›®æ ‡æ–‡æ¡£
     * @param size               éœ€è¦?çš„å…³é”®å?¥çš„ä¸ªæ•°
     * @param sentence_separator åˆ†å‰²ç›®æ ‡æ–‡æ¡£æ—¶çš„å?¥å­?åˆ†å‰²ç¬¦ï¼Œæ­£åˆ™æ ¼å¼?ï¼Œ å¦‚ï¼š[ã€‚ï¼Ÿ?ï¼?!ï¼›;]
     * @return å…³é”®å?¥åˆ—è¡¨
     */
    public static List<String> extractSummary(String document, int size, String sentence_separator)
    {
        return TextRankSentence.getTopSentenceList(document, size, sentence_separator);
    }

    /**
     * è‡ªåŠ¨æ‘˜è¦?
     *
     * @param document           ç›®æ ‡æ–‡æ¡£
     * @param max_length         éœ€è¦?æ‘˜è¦?çš„é•¿åº¦
     * @param sentence_separator åˆ†å‰²ç›®æ ‡æ–‡æ¡£æ—¶çš„å?¥å­?åˆ†å‰²ç¬¦ï¼Œæ­£åˆ™æ ¼å¼?ï¼Œ å¦‚ï¼š[ã€‚ï¼Ÿ?ï¼?!ï¼›;]
     * @return æ‘˜è¦?æ–‡æœ¬
     */
    public static String getSummary(String document, int max_length, String sentence_separator)
    {
        // Parameter size in this method refers to the string length of the summary required;
        // The actual length of the summary generated may be short than the required length, but never longer;
        return TextRankSentence.getSummary(document, max_length, sentence_separator);
    }

}
