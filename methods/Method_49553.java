/** 
 * Run a ScanJob on Hadoop MapReduce. <p> The  {@code confRootField} parameter must be a string in the format{@code package.package...class#fieldname}, where  {@code fieldname} is thename of a public static field on the class specified by the portion of the string before the  {@code #}.  The  {@code #} itself is just a separator andis discarded. <p> When a MapReduce task process prepares to execute the  {@code ScanJob}, it will read the public static field named by  {@code confFieldRoot} and cast it to a{@link ConfigNamespace}.  This namespace object becomes the root of a {@link Configuration} instantiated, populated with the key-value pairsfrom the  {@code conf} parameter, and then passed into the {@code ScanJob}. <p> This method blocks until the ScanJob completes, then returns the metrics generated by the job during its execution.  It does not timeout.
 * @param conf configuration settings for the ScanJob
 * @param confRootField the root of the ScanJob's configuration
 * @param hadoopConf the Configuration passed to the MapReduce Job
 * @param inputFormat the InputFormat&lt;StaticBuffer, Iterable&lt;Entry&gt;&gt;that reads (row, columns) pairs out of a JanusGraph edgestore
 * @param jobName
 * @param mapperClass
 * @return metrics generated by the ScanJob
 * @throws IOException if the job fails for any reason
 * @throws ClassNotFoundException if {@code scanJob.getClass()} or if HadoopMapReduce's internal job-submission-related reflection fails
 * @throws InterruptedException if interrupted while waiting for the HadoopMapReduce job to complete
 */
public static ScanMetrics runJob(Configuration conf,String confRootField,org.apache.hadoop.conf.Configuration hadoopConf,Class<? extends InputFormat> inputFormat,String jobName,Class<? extends Mapper> mapperClass) throws IOException, InterruptedException, ClassNotFoundException {
  Preconditions.checkArgument(null != hadoopConf);
  Preconditions.checkArgument(null != inputFormat);
  if (null != conf) {
    Preconditions.checkArgument(null != confRootField,"Configuration root field must be provided when configuration instance is provided");
  }
  ModifiableHadoopConfiguration scanConf=ModifiableHadoopConfiguration.of(JanusGraphHadoopConfiguration.MAPRED_NS,hadoopConf);
  if (null != confRootField) {
    scanConf.set(JanusGraphHadoopConfiguration.SCAN_JOB_CONFIG_ROOT,confRootField);
    ConfigNamespace confRoot=HadoopScanMapper.getJobRoot(confRootField);
    ModifiableConfiguration hadoopJobConf=ModifiableHadoopConfiguration.prefixView(confRoot,JanusGraphHadoopConfiguration.SCAN_JOB_CONFIG_KEYS,scanConf);
    if (conf != null) {
      Map<String,Object> jobConfMap=conf.getSubset(confRoot);
      for (      Map.Entry<String,Object> jobConfEntry : jobConfMap.entrySet()) {
        hadoopJobConf.set((ConfigOption)ConfigElement.parse(confRoot,jobConfEntry.getKey()).element,jobConfEntry.getValue());
      }
    }
  }
  return runJob(scanConf.getHadoopConfiguration(),inputFormat,jobName,mapperClass);
}
